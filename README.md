# streaming-service
### Проектная работа по потоковой обработке данных
- [Ссылка](https://github.com/ioiimm/de_projects/tree/main/streaming-service)
### Описание проекта
- Приложение для потоковой обработки данных, которое доставляет пользователям агрегатора для доставки еды уведомления об акциях с ограниченным сроком действия.
- Данные читаются из Kafka с помощью Spark Structured Streaming и Python в режиме реального времени и дополняются данными из PostgreSQL.
### Результат
Проект обеспечивает сборку, обработку и последующую отправку данных в Kafka для push-уведомлений пользователям с подпиской, которая позволяет добавлять рестораны в избранное.
### Структура проекта
- `streaming_service.py` - код Spark Structured Streaming приложения



# transaction-metrics
### Проектная работа по аналитическим базам данных в рамках ETL-процесса
- [Ссылка](https://github.com/ioiimm/de_projects/tree/main/transaction-metrics)
### Описание проекта
- Сбор данных по транзакционной активности пользователей из PostgreSQL.
- Обновление таблицы с курсом валют.
- Реализация хранилища в Vertica.
### Результат
Проект успешно решает задачу сбора, обработки и хранения данных из PostgreSQL в Vertica.
### Структура проекта
Внутри `src` расположены папки:
- `/src/dags` - код DAG `1_data_import.py`, который поставляет данные из источника в хранилище. Также код DAG `2_datamart_update.py`, который обновляет витрины данных.
- `/src/sql` - SQL-запрос формирования таблиц в `STAGING`- и `DWH`-слоях, а также скрипт подготовки данных для итоговой витрины.
