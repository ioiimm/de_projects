# streaming-service
## Проектная работа
- [Ссылка](https://github.com/ioiimm/de_projects/tree/main/streaming-service)
## Описание проекта
- Приложение для потоковой обработки данных, которое доставляет пользователям агрегатора для доставки еды уведомления об акциях с ограниченным сроком действия.
- Данные читаются из Kafka с помощью Spark Structured Streaming и Python в режиме реального времени и дополняются данными из PostgreSQL.
## Результат
Проект обеспечивает сборку, обработку и последующую отправку данных в Kafka для push-уведомлений пользователям с подпиской, которая позволяет добавлять рестораны в избранное.
## Структура проекта

# transaction-metrics
## Проектная работа
- [Ссылка](https://github.com/ioiimm/de_projects/tree/main/transaction-metrics)
## Описание проекта
- Сбор данных по транзакционной активности пользователей из Kafka.
- Обновление таблицы с курсом валют.
- Реализация хранилища в Vertica.
## Результат
Проект успешно решает задачу сбора, обработки и хранения потоковых данных из Kafka в Vertica.
## Структура проекта
Внутри `src` расположены папки:
- `/src/dags` - код DAG `1_data_import.py`, который поставляет данные из источника в хранилище. Также код DAG `2_datamart_update.py`, который обновляет витрины данных.
- `/src/sql` - SQL-запрос формирования таблиц в `STAGING`- и `DWH`-слоях, а также скрипт подготовки данных для итоговой витрины.
